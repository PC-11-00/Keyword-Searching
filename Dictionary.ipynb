{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDam3rvnT6YpzrMcqf2rlR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PC-11-00/Keyword-Searching/blob/main/Dictionary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Hw5bRU4Uzg4r"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/DB.json', 'r') as file:\n",
        "    # Load the JSON data\n",
        "    data = json.load(file)\n",
        "\n"
      ],
      "metadata": {
        "id": "77WeWgiX1WpJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AET_j-0PKigS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "descriptions = []"
      ],
      "metadata": {
        "id": "JhnB-I9I4f34"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(data)):\n",
        "  words.append(data[i][\"word\"].lower())\n",
        "  descriptions.append(data[i][\"description\"])\n"
      ],
      "metadata": {
        "id": "rwORcSk44uEu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate Levenshtein distance between two words\n",
        "def levenshtein_distance(word1, word2):\n",
        "    m, n = len(word1), len(word2)\n",
        "    dp = np.zeros((m+1, n+1))\n",
        "\n",
        "    for i in range(m+1):\n",
        "        dp[i][0] = i\n",
        "    for j in range(n+1):\n",
        "        dp[0][j] = j\n",
        "\n",
        "    for i in range(1, m+1):\n",
        "        for j in range(1, n+1):\n",
        "            cost = 0 if word1[i-1] == word2[j-1] else 1\n",
        "            dp[i][j] = min(dp[i-1][j] + 1, dp[i][j-1] + 1, dp[i-1][j-1] + cost)\n",
        "\n",
        "    return dp[m][n]"
      ],
      "metadata": {
        "id": "-b_lSQ3cDkZL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jUeJth_LDmD8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "\n",
        "class TrieNode:\n",
        "    def __init__(self):\n",
        "        self.children = {}  # Mapping from character to child node\n",
        "        self.original_words = set()  # Set to store original words\n",
        "\n",
        "class Trie:\n",
        "    def __init__(self):\n",
        "        self.root = TrieNode()\n",
        "\n",
        "    def insert(self, word):\n",
        "        for i in range(len(word)):\n",
        "            self._insert_suffix(word[i:], word)\n",
        "\n",
        "    def _insert_suffix(self, suffix, original_word):\n",
        "        node = self.root\n",
        "        for char in suffix:\n",
        "            if char not in node.children:\n",
        "                node.children[char] = TrieNode()\n",
        "            node = node.children[char]\n",
        "            node.original_words.add(original_word)\n",
        "\n",
        "    def search(self, word):\n",
        "        node = self.root\n",
        "        for char in word:\n",
        "            if char not in node.children:\n",
        "                return False\n",
        "            node = node.children[char]\n",
        "        return True\n",
        "\n",
        "    def get_original_words(self, suffix):\n",
        "        node = self.root\n",
        "        for char in suffix:\n",
        "            if char not in node.children:\n",
        "                return None\n",
        "            node = node.children[char]\n",
        "        return node.original_words\n",
        "\n",
        "    def get_closest_word(self, word):\n",
        "        min_distance = float('inf')\n",
        "        closest_word = None\n",
        "\n",
        "        # Find all words in the Trie with similar prefix\n",
        "        similar_prefix_words = self._find_similar_prefix_words(word)\n",
        "\n",
        "        if similar_prefix_words:\n",
        "            for original_word in similar_prefix_words:\n",
        "                distance = self._calculate_edit_distance(word, original_word)\n",
        "                if distance < min_distance:\n",
        "                    min_distance = distance\n",
        "                    closest_word = original_word\n",
        "\n",
        "        return closest_word\n",
        "\n",
        "    def _find_similar_prefix_words(self, word):\n",
        "        node = self.root\n",
        "        similar_prefix_words = set()\n",
        "        for char in word:\n",
        "            if char not in node.children:\n",
        "                return similar_prefix_words\n",
        "            node = node.children[char]\n",
        "            similar_prefix_words.update(node.original_words)\n",
        "        return similar_prefix_words\n",
        "\n",
        "    def _calculate_edit_distance(self, word1, word2):\n",
        "        m, n = len(word1), len(word2)\n",
        "        dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "\n",
        "        for i in range(m + 1):\n",
        "            dp[i][0] = i\n",
        "        for j in range(n + 1):\n",
        "            dp[0][j] = j\n",
        "\n",
        "        for i in range(1, m + 1):\n",
        "            for j in range(1, n + 1):\n",
        "                if word1[i - 1] == word2[j - 1]:\n",
        "                    dp[i][j] = dp[i - 1][j - 1]\n",
        "                else:\n",
        "                    dp[i][j] = min(dp[i - 1][j - 1], dp[i - 1][j], dp[i][j - 1]) + 1\n",
        "\n",
        "        return dp[m][n]\n",
        "\n",
        "# Example usage\n",
        "trie = Trie()\n",
        "\n",
        "for word in words:\n",
        "    trie.insert(word)\n",
        "\n"
      ],
      "metadata": {
        "id": "HGmdylM2Fhv3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get closest word\n",
        "closest_word = trie.get_closest_word('pleas')\n",
        "print(\"Closest word:\", closest_word)  # 'apple'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yJoBxjPFn4q",
        "outputId": "df407583-0d10-45a5-f0cd-ddf26710d2ed"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closest word: plead\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8BYt2JxkGABf"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}